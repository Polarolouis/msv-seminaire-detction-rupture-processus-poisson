% !Rnw weave = knitr
% !TeX program = pdfLaTeX
\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{csquotes}
\usepackage{hyperref}
\usepackage{xcolor}

% Booktabs
\usepackage{booktabs}

% Géométrie
\usepackage{geometry}
\geometry{
a4paper, 
total={170mm,257mm},
left=20mm,
top=15mm}

% Maths
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\usepackage{amsfonts}
\usepackage{dsfont}
\usepackage{bm}

% Images 
\usepackage{wrapfig}
\usepackage{graphicx}
\graphicspath{ {./images/} }

% Citations et biblio
\usepackage[backend=biber, style=apa]{biblatex}
%== use and define color ==%
%\usepackage[style=numeric,backend=biber,doi=false,isbn=false,max
\AtEveryCite{\color{blue}}
\addbibresource{references.bib}


% Commande pour les nombres réels
\newcommand{\R}{\mathbb{R}}
\newcommand{\segspace}{\mathcal{T}_K}

\newcommand{\indep}{\perp \!\!\! \perp}

% Commande pour les entiers naturels
\newcommand{\N}{\mathbb{N}}

% Commande pour les entiers relatifs
\newcommand{\Z}{\mathbb{Z}}

% Commande pour les nombres complexes
\newcommand{\C}{\mathbb{C}}

% Commande pour la probabilité
\newcommand{\Prob}{\mathbb{P}}

% Commande pour l'espérance
\newcommand{\E}{\mathbb{E}}

% Commande pour la variance
\newcommand{\Var}{\text{Var}}

% Commande pour la covariance
\newcommand{\Cov}{\text{Cov}}

% Commande pour la convergence en probabilité
\newcommand{\convprob}{\xrightarrow{P}}

% Commande pour la convergence en loi
\newcommand{\convloi}{\xrightarrow{d}}

% Commande pour la convergence en moyenne quadratique
\newcommand{\convmq}{\xrightarrow{L^2}}

% Poisson
\newcommand{\Poisson}[1]{\mathcal{P} ({#1})}

% Pagination
\usepackage{fancyhdr}
\pagestyle{fancy}
% Place Page X of Y on the right-hand
% side of the footer
\fancyhf{}
\rfoot{\thepage}

\title{\vspace{-1.5cm}\large Détection de ruptures dans des processus de Poisson - Stéphane Robin\\
\small Compte-rendu du séminaire\vspace{-0.5cm}}
\date{\small 30 Jan. 2024}
\author{\small Louis Lacoste}

<<include=FALSE>>=
    knitr::opts_chunk$set(echo = FALSE)
    require("knitr", quietly = TRUE)
    options(knitr.table.format = "latex")
@

\begin{document}
\maketitle

Ce compte-rendu concerne la présentation \cite{robinChangepointDetectionPoisson2019}.
\section{Introduction}

\begin{wrapfigure}[14]{L}{0.27\textwidth}
    \centering
    \vspace{-5pt}
    \includegraphics[width=0.27\textwidth]{graph-cris-chauve-souris}
    \vspace{-20pt}
    \caption{\small Comptage de cris de chauve-souris (nuit du 17 juillet 2019)}
    \label{fig:graph-cris-chauve-souris}
\end{wrapfigure}

Stéphane Robin nous présente une méthode qu'ils ont développé avec Emilie Lebarbier
et Charlotte Dion-Blanc. Cette méthode est présentée dans l'article 
\cite{dion-blancDetectionRupturesMultiples2023} sur HAL.

\begin{wrapfigure}[14]{R}{0.27\textwidth}
    \centering
    \vspace{-20pt}
    \includegraphics[width=0.27\textwidth]{graph-eruption-kilauea}
    \vspace{-20pt}
    \caption{Données d'éruption du Kilauea, 1750 - 1984}
    \label{fig:graph-eruption-kilauea}
\end{wrapfigure}

La méthode considère des données de comptages au cours du temps. Un exemple de 
telles données est celui du nombre de cris de chauve-souris au cours de la nuit.
Ces données sont présentées dans sur la figure~\ref{fig:graph-cris-chauve-souris}.
Ou encore les données d'éruption du volcan Kilauea présentée sur la figure~\ref{fig:graph-eruption-kilauea}.

L'intervalle de temps est normalisé, $t\in[0,1]$ et les instants d'évènements 
sont les $0<T_1<\dots T_i<\dots T_n < 1$.
Étant donné qu'il s'agit d'un comptage aléatoire, le processus \emph{naturel}\footnote{Au sens du premier qui vienne à l'esprit.}
est le processus de comptage, $N(t) = \sum_{i=1}^n \mathds{1}_{T_i \leq t}$ et 
parmi les processus de comptage, le processus de Poisson défini par sa fonction 
d'intensité $\lambda(t)$.\\

\section{Méthode}

La méthode fait l'hypothèse que la fonction d'intensité est constante par 
morceaux et qu'il existe des \emph{points de ruptures} les $(\tau_k)_{0\leq k \leq K}$.
Et alors pour $t \in I_k = ] \tau_{k-1}; \tau_{k} ], \lambda(t) = \lambda_k$.
Ainsi l'objectif de la méthode est d'estimer les paramètres 
$\theta =((\tau_k)_{0\leq k \leq K}, (\lambda_k)_{0\leq k \leq K} )$ et de 
réaliser une \emph{sélection de modèle} pour obtenir le nombre de segments $K$.

\subsection{Segmentation}

Un rappel sur la segmentation en temps discret, nous montre que la programmation
dynamique permet ainsi de résoudre le problème d'estimation des paramètres dans 
ce cas qui semblait apparemment computationnellement complexe.

Dans le cas de la méthode, c'est à dire le temps \emph{continu}, le problème d'optimisation est 
$$(\widehat{\bm{\tau}}, \widehat{\bm{\lambda}}) = 
\argmin_{\bm{\tau}\in\segspace, \bm{\lambda} \in (\R^+)^K} \gamma (\bm{\tau}, \bm{\lambda})$$

L'additivité du contraste: $\gamma(\bm\tau, \bm\lambda) = 
\sum_{k=1}^K C(\Delta N_k, \Delta\tau_k, \lambda_k)$ en tant que somme sur les 
segments aide à la résolution du problème d'optimisation.
En effet le $\bm \lambda = (\lambda_1, \dots, \lambda_K)$ optimal peut être estimé grâce à la propriété d'additivité
en résolvant $\widehat \lambda_k = \lambda_k (\tau) = \argmin_{\lambda_k \in \R^+} 
C(\Delta N_k, \Delta\tau_k)$.
Et si la fonction de contraste est la log-vraisemblance négative, on a : 
$\widehat \lambda_k = \Delta N_k / \Delta \tau_k$.

Mais le problème difficile est celui de trouver le $\bm\tau = (\tau_0, \dots, 
\tau_K)$ optimal, car le problème 
d'optimisation est alors $\widehat \tau = 
\argmin_{\tau\in\segspace} \widehat \gamma(\tau), 
\widehat \gamma(\tau) = \gamma (\tau, \widehat \lambda (\tau))$ où $\segspace$ 
est l'espace de segmentation \textbf{continu}, $$\segspace = 
\bigl\{ \tau \in [0,1]^{K+1} : 0 = \tau_0 < \tau_1 \dots < \tau_{K-1} < 
\tau_K = 1 \bigr\}$$

Car le contraste n'est ni convexe ni continu par rapport à $\tau$.

La figure~\ref{fig:contrast-function} présente les valeurs de la fonction de 
contraste pour les paramètres donnés. Sur la figure, chaque "bloc" correspond à
une partition des nombre d'évènements $\Delta N = (\Delta N_1, \Delta N_2, 
\Delta N_3)$.

L'idée est alors de partitionner le nombre d'évènements  $\mathcal{N} = 
\bigl\{ \nu \in \N^K : \sum_{k=1}^K \nu_k = n \bigr\}$ où $\nu_k$ est le nombre
d'évènements dans le segment k. Puis à partir de cette partition, on peut 
partitionner l'espace de segmentation $\mathcal{T}(\nu) = 
\bigl\{ \bm \tau \in \segspace : \Delta N = \nu \bigr\}$ qui satisfait la 
partition $\nu$. Ce qui permet de réécrire le problème de minimisation :
$$\min_{\bm{\tau}\in\segspace} \widehat \gamma (\bm{\tau}) = \min_{\nu \in 
\mathcal{N}^K} \min_{\bm{\tau}\in\mathcal{T}(\nu)} \widehat \gamma (\bm{\tau})$$

\begin{wrapfigure}[28]{L}{0.25\textwidth}
    \vspace{-12pt}
    \centering
    \caption{Fonction de contraste et partitionnement de l'espace pour $n=10$, $K=3$ et $\tau = (\tau_1,\tau_2)$}
    \label{fig:contrast-function}
    \includegraphics[width=0.25\textwidth]{contrast-function}
    \includegraphics[width=0.25\textwidth]{space-partitioning}
\end{wrapfigure}

Et alors grâce aux propriétés de stricte concavité des fonctions de coût $C$ par
rapport aux $\Delta \tau_k$ les auteurs montrent que $\hat{\tau} = 
\argmin_{\tau\in\segspace} \hat{\gamma}(\bm{\tau}) \subset \bigl\{ T^-_1, T_1, 
\dots, T^-_n, T_n \bigr\}$\footnote{$T_i^-$ représente l'instant juste avant le saut
au temps $T_i$.}. Et ainsi, la programmation dynamique permet de trouver
les points de ruptures avec une complexité au plus $\mathcal{O}(n^2)$.

Un contraste concave par rapport à $\Delta\tau$ est dit admissible (par exemple
les contrastes de Poisson et Poisson-Gamma). Voici le contraste de Poisson :

$$C_P(\nu_k, \Delta\tau_k) = \nu_k(1-\log \nu_k + \log \Delta\tau_k)$$

Et un contraste est dit désirable
s'il n'autorise pas les segments de longueur nulle (et c'est le cas du 
Poisson-Gamma).

Voici donc la formule du contraste Poisson-Gamma :

$$C_{PG}(\nu_k, \Delta\tau_k)=-\log\Gamma(a+\nu_k)+(a+\nu_k)\log(b+\nu_k)$$

qui satisfait les deux propriétés, d'admissibilité et de désirabilité.

Celle-ci dérive du modèle Poisson-Gamma qui dit que pour chaque segment 
$1\leq k \leq K$ :
$$\lambda_k \overset{iid}{\sim} \mathcal{G}am(a,b), (N(t))_{t\in I_k} \sim PP(\lambda_k)$$

\subsection{Sélection de modèle}

Pour la sélection de modèle la propriété de \emph{thinning} du processus de 
Poisson permet d'obtenir deux processus de Poisson indépendants et donc 
de pouvoir faire de la \emph{cross-validation}.

En effet, en sélectionnant chaque point avec une probabilité $f$ pour faire 
partie du jeu d'entraînement et en sélectionnant donc avec probabilité $1-f$ 
ceux faisant partie du jeu de test on obtient deux processus de Poisson 
indépendants.

$$N^L(t) \sim PP(f \lambda(t)) \indep N^T(t) \sim PP((1-f) \lambda(t))$$

Et alors on peut répéter cette procédure $M$ fois, estimer les paramètres sur le 
jeu d'apprentissage, 
puis moyenner les contrastes obtenus. 
Pour chaque $m$ on a $\gamma^{T,m}_K = \gamma \bigl( N^T(t);\hat{\tau}^{L,m},\frac{1-f}{f}\hat{\lambda}^{L,m} \bigr)$

On a alors accès à $\bar{\gamma}_K = \frac{1}{K} \sum_{m=1}^M \gamma^{T,m}_K$ et
on peut alors sélectionner :
$$\hat{K} = \argmin_K \bar{\gamma}_K$$

\subsection{Extension : Processus de Poisson marqué}

Le processus de Poisson marqué est une extension et la méthode de détection de
rupture peut gérer ces données supplémentaires.

Un processus de Poisson est dit marqué si à chaque temps de saut $T_i$ est 
associé une "marque". Pour l'exemple des volcans, il s'agit de la durée de l'
éruption et pour les cris de chauve-souris, il peut s'agir soit de l'espèce ou 
encore de la durée du cri.

Mathématiquement, cela peut se noter : 
$$(Y(t))_{0\leq t \leq 1} \sim MPP(\lambda(t), \mu(t)),$$ 
qui consiste en deux composantes :
$$(N(t))_{0\leq t \leq 1} \sim PP(\lambda(t)), X_i \sim \underbrace{\mathcal{F}}_{\text{loi de probabilité}}(\mu(T_i))$$

Et dans la présentation, on peut ainsi voir que sur un exemple d'éruption de 
l'Etna, la prise en compte des marques modifie l'estimation des paramètres. Ce 
qui dans le cas du volcan pourrait indiquer des modifications de son activité
sous-jacente.

\section{Apport personnel}
<<apport-perso, child='apport-perso.Rnw'>>=
@

\printbibliography
\nocite{*}

\end{document}